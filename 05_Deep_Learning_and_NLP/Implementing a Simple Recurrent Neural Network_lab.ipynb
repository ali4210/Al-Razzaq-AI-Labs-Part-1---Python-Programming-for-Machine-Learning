{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-16T12:22:06.330759Z",
     "start_time": "2025-12-16T12:22:04.281861Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.optimizers import Adam"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:22:50.369061Z",
     "start_time": "2025-12-16T12:22:50.325957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=10, input_shape=(None, 1)))\n",
    "model.add(Dense(units=1))"
   ],
   "id": "8cfcd8ee8f2d7fde",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\PycharmProjects\\pythonProject3\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:23:09.824363Z",
     "start_time": "2025-12-16T12:23:09.816069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = np.array([[[i+j] for i in range(5)] for j in range(1000)], dtype=float)\n",
    "y_train = np.array([[i+5] for i in range(1000)], dtype=float)"
   ],
   "id": "bdbe4d973aa6f4e9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:23:24.028891Z",
     "start_time": "2025-12-16T12:23:24.022405Z"
    }
   },
   "cell_type": "code",
   "source": "model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')",
   "id": "17b118eba5d57847",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:24:03.098564Z",
     "start_time": "2025-12-16T12:23:57.961562Z"
    }
   },
   "cell_type": "code",
   "source": "model.fit(X_train, y_train, epochs=100, batch_size=32)",
   "id": "221e0cc3d28554d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 335322.6875   \n",
      "Epoch 2/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 331819.2188 \n",
      "Epoch 3/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 328360.1250 \n",
      "Epoch 4/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 959us/step - loss: 324915.9062\n",
      "Epoch 5/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 946us/step - loss: 321562.8750\n",
      "Epoch 6/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 939us/step - loss: 318240.2188\n",
      "Epoch 7/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 939us/step - loss: 314921.6875\n",
      "Epoch 8/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 980us/step - loss: 311645.5938\n",
      "Epoch 9/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 979us/step - loss: 308361.7500\n",
      "Epoch 10/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 977us/step - loss: 305152.0625\n",
      "Epoch 11/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 965us/step - loss: 301952.6250\n",
      "Epoch 12/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 952us/step - loss: 298797.8438\n",
      "Epoch 13/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 931us/step - loss: 295682.0938\n",
      "Epoch 14/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 936us/step - loss: 292571.2188\n",
      "Epoch 15/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 931us/step - loss: 289509.9688\n",
      "Epoch 16/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 920us/step - loss: 286493.2188\n",
      "Epoch 17/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 934us/step - loss: 283486.9062\n",
      "Epoch 18/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 939us/step - loss: 280521.5625\n",
      "Epoch 19/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 962us/step - loss: 277581.3750\n",
      "Epoch 20/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 896us/step - loss: 274677.6875\n",
      "Epoch 21/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 910us/step - loss: 271807.2188\n",
      "Epoch 22/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 953us/step - loss: 268968.3125\n",
      "Epoch 23/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 897us/step - loss: 266145.8125\n",
      "Epoch 24/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 922us/step - loss: 263357.0312\n",
      "Epoch 25/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 937us/step - loss: 260601.9062\n",
      "Epoch 26/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 919us/step - loss: 257867.8594\n",
      "Epoch 27/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 948us/step - loss: 255174.3906\n",
      "Epoch 28/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 982us/step - loss: 252506.2969\n",
      "Epoch 29/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 963us/step - loss: 249853.5625\n",
      "Epoch 30/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 988us/step - loss: 247228.5312\n",
      "Epoch 31/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 994us/step - loss: 244629.6406\n",
      "Epoch 32/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 966us/step - loss: 242047.5156\n",
      "Epoch 33/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 927us/step - loss: 239487.6875\n",
      "Epoch 34/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 911us/step - loss: 236942.9844\n",
      "Epoch 35/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 909us/step - loss: 234456.0938\n",
      "Epoch 36/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 942us/step - loss: 231970.2812\n",
      "Epoch 37/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 945us/step - loss: 229511.8750\n",
      "Epoch 38/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 960us/step - loss: 227063.4219\n",
      "Epoch 39/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 932us/step - loss: 224661.2344\n",
      "Epoch 40/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 919us/step - loss: 222255.1719\n",
      "Epoch 41/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 926us/step - loss: 219897.1719\n",
      "Epoch 42/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 895us/step - loss: 217535.1719\n",
      "Epoch 43/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 215209.5469 \n",
      "Epoch 44/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 912us/step - loss: 212913.0938\n",
      "Epoch 45/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 902us/step - loss: 210622.8906\n",
      "Epoch 46/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 968us/step - loss: 208374.5781\n",
      "Epoch 47/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 952us/step - loss: 206123.2656\n",
      "Epoch 48/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 945us/step - loss: 203905.6406\n",
      "Epoch 49/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 945us/step - loss: 201713.2812\n",
      "Epoch 50/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 944us/step - loss: 199513.5312\n",
      "Epoch 51/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 911us/step - loss: 197383.4531\n",
      "Epoch 52/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 904us/step - loss: 195256.9688\n",
      "Epoch 53/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 921us/step - loss: 193153.9531\n",
      "Epoch 54/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 964us/step - loss: 191080.4688\n",
      "Epoch 55/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 926us/step - loss: 189011.3438\n",
      "Epoch 56/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 920us/step - loss: 186933.2656\n",
      "Epoch 57/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 944us/step - loss: 184886.4375\n",
      "Epoch 58/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 948us/step - loss: 182871.0938\n",
      "Epoch 59/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 945us/step - loss: 180859.7188\n",
      "Epoch 60/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 940us/step - loss: 178893.7031\n",
      "Epoch 61/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 959us/step - loss: 176956.4844\n",
      "Epoch 62/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 970us/step - loss: 175032.0781\n",
      "Epoch 63/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 975us/step - loss: 173148.7188\n",
      "Epoch 64/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 949us/step - loss: 171239.2188\n",
      "Epoch 65/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 941us/step - loss: 169348.0000\n",
      "Epoch 66/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 912us/step - loss: 167490.0000\n",
      "Epoch 67/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 923us/step - loss: 165635.1094\n",
      "Epoch 68/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 958us/step - loss: 163815.0938\n",
      "Epoch 69/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 893us/step - loss: 162004.6562\n",
      "Epoch 70/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 919us/step - loss: 160219.6562\n",
      "Epoch 71/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 914us/step - loss: 158443.1562\n",
      "Epoch 72/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 922us/step - loss: 156687.4844\n",
      "Epoch 73/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 921us/step - loss: 154952.3906\n",
      "Epoch 74/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 921us/step - loss: 153237.9062\n",
      "Epoch 75/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 921us/step - loss: 151529.9688\n",
      "Epoch 76/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 922us/step - loss: 149899.4844\n",
      "Epoch 77/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 918us/step - loss: 148362.3438\n",
      "Epoch 78/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 901us/step - loss: 146503.2969\n",
      "Epoch 79/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 910us/step - loss: 144863.0781\n",
      "Epoch 80/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 909us/step - loss: 143236.2500\n",
      "Epoch 81/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 904us/step - loss: 141623.7188\n",
      "Epoch 82/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 899us/step - loss: 139998.4375\n",
      "Epoch 83/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 899us/step - loss: 138419.7812\n",
      "Epoch 84/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 896us/step - loss: 136833.4531\n",
      "Epoch 85/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 900us/step - loss: 135280.0938\n",
      "Epoch 86/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 916us/step - loss: 133746.9531\n",
      "Epoch 87/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 910us/step - loss: 132220.7188\n",
      "Epoch 88/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 909us/step - loss: 130693.0078\n",
      "Epoch 89/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 929us/step - loss: 129178.2891\n",
      "Epoch 90/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 946us/step - loss: 127702.2031\n",
      "Epoch 91/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 908us/step - loss: 126218.2734\n",
      "Epoch 92/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 927us/step - loss: 124746.7812\n",
      "Epoch 93/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 892us/step - loss: 123302.0625\n",
      "Epoch 94/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 900us/step - loss: 121849.4922\n",
      "Epoch 95/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 895us/step - loss: 120449.5703\n",
      "Epoch 96/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 921us/step - loss: 119059.5938\n",
      "Epoch 97/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 117659.7109 \n",
      "Epoch 98/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 116307.2812 \n",
      "Epoch 99/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 114946.5391 \n",
      "Epoch 100/100\n",
      "\u001B[1m32/32\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 906us/step - loss: 113593.5703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d0d7c84050>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:24:22.152668Z",
     "start_time": "2025-12-16T12:24:22.040692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test = np.array([[[i+j] for i in range(5)] for j in range(100, 110)], dtype=float)\n",
    "y_test = np.array([[i+5] for i in range(100, 110)], dtype=float)\n",
    "\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")"
   ],
   "id": "beaccf4f7644c269",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 87ms/step - loss: 17.2397\n",
      "Test Loss: 17.239709854125977\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T12:24:37.043437Z",
     "start_time": "2025-12-16T12:24:36.957722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Predictions: \", y_pred.flatten())"
   ],
   "id": "4d5e0858b946c00b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step\n",
      "Predictions:  [100.32138  101.02854  101.83694  102.84677  104.13729  105.71283\n",
      " 107.462234 109.18333  110.675934 111.83133 ]\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
